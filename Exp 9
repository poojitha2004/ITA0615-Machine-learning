# Import required libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score, mean_squared_error

# Create dataset (non-linear relationship)
X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)
y = np.array([3, 5, 7, 10, 15, 21, 28, 36, 45, 55])

# ---------------- Linear Regression ----------------
linear_model = LinearRegression()
linear_model.fit(X, y)
y_linear_pred = linear_model.predict(X)

# ---------------- Polynomial Regression (Degree = 2) ----------------
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)

poly_model = LinearRegression()
poly_model.fit(X_poly, y)
y_poly_pred = poly_model.predict(X_poly)

# ---------------- Evaluation ----------------
print("Linear Regression Performance")
print("R² Score:", r2_score(y, y_linear_pred))
print("MSE:", mean_squared_error(y, y_linear_pred))

print("\nPolynomial Regression Performance")
print("R² Score:", r2_score(y, y_poly_pred))
print("MSE:", mean_squared_error(y, y_poly_pred))

# ---------------- Plot Results ----------------
plt.scatter(X, y, color='black', label='Actual Data')
plt.plot(X, y_linear_pred, color='red', label='Linear Regression')
plt.plot(X, y_poly_pred, color='blue', label='Polynomial Regression (degree 2)')
plt.xlabel("X")
plt.ylabel("y")
plt.title("Linear vs Polynomial Regression")
plt.legend()
plt.show()
